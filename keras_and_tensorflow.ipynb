{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks with keras and tensorflow\n",
    "\n",
    "N.B. You will need to pip install keras and tensorflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lesson we'll use sklearn's built-in breast cancer dataset. The next cell loads the data and prints the data description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting our data and initializing a Scaler\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "\n",
    "X_train_s = ss.transform(X_train)\n",
    "X_test_s = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 30), (143, 30))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_s.shape, X_test_s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing a Neural Network in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing model and layer types\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optimizer\n",
    "\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model = Sequential()\n",
    "\n",
    "# how many input neurons do you want\n",
    "inputs = X_train_s.shape[1]\n",
    "\n",
    "# how many hidden neurons in the hidden layer\n",
    "hiddens = inputs\n",
    "\n",
    "# input to hidden\n",
    "model.add(Dense(hiddens, activation='relu', input_dim=inputs))\n",
    "\n",
    "# hidden to output\n",
    "model.add(Dense(1))\n",
    "\n",
    "# initialize optimizer\n",
    "adam = Adam()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=adam, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples, validate on 143 samples\n",
      "Epoch 1/100\n",
      "426/426 [==============================] - 0s 336us/step - loss: 0.5744 - val_loss: 0.5272\n",
      "Epoch 2/100\n",
      "426/426 [==============================] - 0s 56us/step - loss: 0.3450 - val_loss: 0.3422\n",
      "Epoch 3/100\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.2472 - val_loss: 0.2634\n",
      "Epoch 4/100\n",
      "426/426 [==============================] - 0s 54us/step - loss: 0.1896 - val_loss: 0.2180\n",
      "Epoch 5/100\n",
      "426/426 [==============================] - 0s 55us/step - loss: 0.1571 - val_loss: 0.1885\n",
      "Epoch 6/100\n",
      "426/426 [==============================] - 0s 49us/step - loss: 0.1360 - val_loss: 0.1654\n",
      "Epoch 7/100\n",
      "426/426 [==============================] - 0s 50us/step - loss: 0.1210 - val_loss: 0.1524\n",
      "Epoch 8/100\n",
      "426/426 [==============================] - 0s 52us/step - loss: 0.1084 - val_loss: 0.1387\n",
      "Epoch 9/100\n",
      "426/426 [==============================] - 0s 46us/step - loss: 0.0985 - val_loss: 0.1284\n",
      "Epoch 10/100\n",
      "426/426 [==============================] - 0s 50us/step - loss: 0.0911 - val_loss: 0.1234\n",
      "Epoch 11/100\n",
      "426/426 [==============================] - 0s 57us/step - loss: 0.0855 - val_loss: 0.1141\n",
      "Epoch 12/100\n",
      "426/426 [==============================] - 0s 53us/step - loss: 0.0809 - val_loss: 0.1086\n",
      "Epoch 13/100\n",
      "426/426 [==============================] - 0s 48us/step - loss: 0.0759 - val_loss: 0.1026\n",
      "Epoch 14/100\n",
      "426/426 [==============================] - 0s 51us/step - loss: 0.0732 - val_loss: 0.1009\n",
      "Epoch 15/100\n",
      "426/426 [==============================] - 0s 45us/step - loss: 0.0695 - val_loss: 0.0953\n",
      "Epoch 16/100\n",
      "426/426 [==============================] - 0s 52us/step - loss: 0.0671 - val_loss: 0.0919\n",
      "Epoch 17/100\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.0654 - val_loss: 0.0900\n",
      "Epoch 18/100\n",
      "426/426 [==============================] - 0s 57us/step - loss: 0.0624 - val_loss: 0.0871\n",
      "Epoch 19/100\n",
      "426/426 [==============================] - 0s 58us/step - loss: 0.0604 - val_loss: 0.0830\n",
      "Epoch 20/100\n",
      "426/426 [==============================] - 0s 60us/step - loss: 0.0585 - val_loss: 0.0855\n",
      "Epoch 21/100\n",
      "426/426 [==============================] - 0s 51us/step - loss: 0.0570 - val_loss: 0.0803\n",
      "Epoch 22/100\n",
      "426/426 [==============================] - 0s 57us/step - loss: 0.0540 - val_loss: 0.0788\n",
      "Epoch 23/100\n",
      "426/426 [==============================] - 0s 57us/step - loss: 0.0536 - val_loss: 0.0804\n",
      "Epoch 24/100\n",
      "426/426 [==============================] - 0s 58us/step - loss: 0.0502 - val_loss: 0.0752\n",
      "Epoch 25/100\n",
      "426/426 [==============================] - 0s 58us/step - loss: 0.0494 - val_loss: 0.0740\n",
      "Epoch 26/100\n",
      "426/426 [==============================] - 0s 55us/step - loss: 0.0477 - val_loss: 0.0749\n",
      "Epoch 27/100\n",
      "426/426 [==============================] - 0s 61us/step - loss: 0.0465 - val_loss: 0.0723\n",
      "Epoch 28/100\n",
      "426/426 [==============================] - 0s 52us/step - loss: 0.0454 - val_loss: 0.0710\n",
      "Epoch 29/100\n",
      "426/426 [==============================] - 0s 60us/step - loss: 0.0452 - val_loss: 0.0707\n",
      "Epoch 30/100\n",
      "426/426 [==============================] - 0s 53us/step - loss: 0.0431 - val_loss: 0.0688\n",
      "Epoch 31/100\n",
      "426/426 [==============================] - 0s 56us/step - loss: 0.0424 - val_loss: 0.0683\n",
      "Epoch 32/100\n",
      "426/426 [==============================] - 0s 56us/step - loss: 0.0419 - val_loss: 0.0684\n",
      "Epoch 33/100\n",
      "426/426 [==============================] - 0s 65us/step - loss: 0.0404 - val_loss: 0.0654\n",
      "Epoch 34/100\n",
      "426/426 [==============================] - 0s 53us/step - loss: 0.0394 - val_loss: 0.0682\n",
      "Epoch 35/100\n",
      "426/426 [==============================] - 0s 56us/step - loss: 0.0390 - val_loss: 0.0679\n",
      "Epoch 36/100\n",
      "426/426 [==============================] - 0s 58us/step - loss: 0.0385 - val_loss: 0.0645\n",
      "Epoch 37/100\n",
      "426/426 [==============================] - 0s 58us/step - loss: 0.0372 - val_loss: 0.0693\n",
      "Epoch 38/100\n",
      "426/426 [==============================] - 0s 52us/step - loss: 0.0372 - val_loss: 0.0646\n",
      "Epoch 39/100\n",
      "426/426 [==============================] - 0s 55us/step - loss: 0.0370 - val_loss: 0.0640\n",
      "Epoch 40/100\n",
      "426/426 [==============================] - 0s 52us/step - loss: 0.0354 - val_loss: 0.0656\n",
      "Epoch 41/100\n",
      "426/426 [==============================] - 0s 54us/step - loss: 0.0345 - val_loss: 0.0655\n",
      "Epoch 42/100\n",
      "426/426 [==============================] - 0s 56us/step - loss: 0.0343 - val_loss: 0.0641\n",
      "Epoch 43/100\n",
      "426/426 [==============================] - 0s 49us/step - loss: 0.0341 - val_loss: 0.0648\n",
      "Epoch 44/100\n",
      "426/426 [==============================] - 0s 56us/step - loss: 0.0332 - val_loss: 0.0627\n",
      "Epoch 45/100\n",
      "426/426 [==============================] - 0s 49us/step - loss: 0.0328 - val_loss: 0.0639\n",
      "Epoch 46/100\n",
      "426/426 [==============================] - 0s 49us/step - loss: 0.0320 - val_loss: 0.0646\n",
      "Epoch 47/100\n",
      "426/426 [==============================] - 0s 50us/step - loss: 0.0316 - val_loss: 0.0633\n",
      "Epoch 48/100\n",
      "426/426 [==============================] - 0s 51us/step - loss: 0.0319 - val_loss: 0.0641\n",
      "Epoch 49/100\n",
      "426/426 [==============================] - 0s 54us/step - loss: 0.0316 - val_loss: 0.0644\n",
      "Epoch 50/100\n",
      "426/426 [==============================] - 0s 53us/step - loss: 0.0307 - val_loss: 0.0624\n",
      "Epoch 51/100\n",
      "426/426 [==============================] - 0s 51us/step - loss: 0.0298 - val_loss: 0.0644\n",
      "Epoch 52/100\n",
      "426/426 [==============================] - 0s 58us/step - loss: 0.0292 - val_loss: 0.0626\n",
      "Epoch 53/100\n",
      "426/426 [==============================] - 0s 51us/step - loss: 0.0293 - val_loss: 0.0635\n",
      "Epoch 54/100\n",
      "426/426 [==============================] - 0s 48us/step - loss: 0.0292 - val_loss: 0.0659\n",
      "Epoch 55/100\n",
      "426/426 [==============================] - 0s 52us/step - loss: 0.0281 - val_loss: 0.0610\n",
      "Epoch 56/100\n",
      "426/426 [==============================] - 0s 54us/step - loss: 0.0276 - val_loss: 0.0643\n",
      "Epoch 57/100\n",
      "426/426 [==============================] - 0s 57us/step - loss: 0.0278 - val_loss: 0.0639\n",
      "Epoch 58/100\n",
      "426/426 [==============================] - 0s 50us/step - loss: 0.0272 - val_loss: 0.0616\n",
      "Epoch 59/100\n",
      "426/426 [==============================] - 0s 48us/step - loss: 0.0273 - val_loss: 0.0634\n",
      "Epoch 60/100\n",
      "426/426 [==============================] - 0s 50us/step - loss: 0.0265 - val_loss: 0.0646\n",
      "Epoch 61/100\n",
      "426/426 [==============================] - 0s 51us/step - loss: 0.0269 - val_loss: 0.0611\n",
      "Epoch 62/100\n",
      "426/426 [==============================] - 0s 52us/step - loss: 0.0259 - val_loss: 0.0623\n",
      "Epoch 63/100\n",
      "426/426 [==============================] - 0s 56us/step - loss: 0.0253 - val_loss: 0.0634\n",
      "Epoch 64/100\n",
      "426/426 [==============================] - 0s 51us/step - loss: 0.0253 - val_loss: 0.0626\n",
      "Epoch 65/100\n",
      "426/426 [==============================] - 0s 53us/step - loss: 0.0249 - val_loss: 0.0627\n",
      "Epoch 66/100\n",
      "426/426 [==============================] - 0s 56us/step - loss: 0.0244 - val_loss: 0.0624\n",
      "Epoch 67/100\n",
      "426/426 [==============================] - 0s 55us/step - loss: 0.0243 - val_loss: 0.0618\n",
      "Epoch 68/100\n",
      "426/426 [==============================] - 0s 53us/step - loss: 0.0241 - val_loss: 0.0625\n",
      "Epoch 69/100\n",
      "426/426 [==============================] - 0s 53us/step - loss: 0.0239 - val_loss: 0.0621\n",
      "Epoch 70/100\n",
      "426/426 [==============================] - 0s 57us/step - loss: 0.0237 - val_loss: 0.0616\n",
      "Epoch 71/100\n",
      "426/426 [==============================] - 0s 54us/step - loss: 0.0232 - val_loss: 0.0640\n",
      "Epoch 72/100\n",
      "426/426 [==============================] - 0s 58us/step - loss: 0.0229 - val_loss: 0.0611\n",
      "Epoch 73/100\n",
      "426/426 [==============================] - 0s 53us/step - loss: 0.0232 - val_loss: 0.0631\n",
      "Epoch 74/100\n",
      "426/426 [==============================] - 0s 51us/step - loss: 0.0229 - val_loss: 0.0632\n",
      "Epoch 75/100\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.0221 - val_loss: 0.0626\n",
      "Epoch 76/100\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.0216 - val_loss: 0.0611\n",
      "Epoch 77/100\n",
      "426/426 [==============================] - 0s 49us/step - loss: 0.0215 - val_loss: 0.0646\n",
      "Epoch 78/100\n",
      "426/426 [==============================] - 0s 46us/step - loss: 0.0212 - val_loss: 0.0630\n",
      "Epoch 79/100\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.0211 - val_loss: 0.0612\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 49us/step - loss: 0.0213 - val_loss: 0.0645\n",
      "Epoch 81/100\n",
      "426/426 [==============================] - 0s 48us/step - loss: 0.0204 - val_loss: 0.0618\n",
      "Epoch 82/100\n",
      "426/426 [==============================] - 0s 45us/step - loss: 0.0206 - val_loss: 0.0609\n",
      "Epoch 83/100\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.0200 - val_loss: 0.0634\n",
      "Epoch 84/100\n",
      "426/426 [==============================] - 0s 46us/step - loss: 0.0201 - val_loss: 0.0631\n",
      "Epoch 85/100\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.0195 - val_loss: 0.0647\n",
      "Epoch 86/100\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.0197 - val_loss: 0.0633\n",
      "Epoch 87/100\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.0192 - val_loss: 0.0637\n",
      "Epoch 88/100\n",
      "426/426 [==============================] - 0s 45us/step - loss: 0.0196 - val_loss: 0.0628\n",
      "Epoch 89/100\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.0194 - val_loss: 0.0634\n",
      "Epoch 90/100\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.0194 - val_loss: 0.0643\n",
      "Epoch 91/100\n",
      "426/426 [==============================] - 0s 50us/step - loss: 0.0189 - val_loss: 0.0619\n",
      "Epoch 92/100\n",
      "426/426 [==============================] - 0s 46us/step - loss: 0.0185 - val_loss: 0.0628\n",
      "Epoch 93/100\n",
      "426/426 [==============================] - 0s 51us/step - loss: 0.0183 - val_loss: 0.0628\n",
      "Epoch 94/100\n",
      "426/426 [==============================] - 0s 51us/step - loss: 0.0181 - val_loss: 0.0645\n",
      "Epoch 95/100\n",
      "426/426 [==============================] - 0s 48us/step - loss: 0.0182 - val_loss: 0.0615\n",
      "Epoch 96/100\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.0180 - val_loss: 0.0631\n",
      "Epoch 97/100\n",
      "426/426 [==============================] - 0s 50us/step - loss: 0.0175 - val_loss: 0.0619\n",
      "Epoch 98/100\n",
      "426/426 [==============================] - 0s 49us/step - loss: 0.0176 - val_loss: 0.0639\n",
      "Epoch 99/100\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.0181 - val_loss: 0.0656\n",
      "Epoch 100/100\n",
      "426/426 [==============================] - 0s 49us/step - loss: 0.0179 - val_loss: 0.0628\n"
     ]
    }
   ],
   "source": [
    "# Fitting our model\n",
    "history = model.fit(X_train_s, y_train, validation_data=(X_test_s, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a2b5f9278>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xt8XWWd7/HPb98vuTWXpmnSS0pbSrm1UNtyAJGL2AJSBGUAEetROZ6RlzgjjuXMjCM4zqjjQcfXVBhQOA4qiCBYlKFoKXJRCgFL6ZWmF5r0kqa5X/Z9P+ePZ6dN051mN026s3d+79crr2avvbL2b2U13/WsZ631LDHGoJRSKr84sl2AUkqpkafhrpRSeUjDXSml8pCGu1JK5SENd6WUykMa7koplYcyCncRWSIi20SkXkRWDDLPjSKyWUQ2icgvRrZMpZRSJ0KGus5dRJzAe8CHgUbgTeBmY8zmfvPMAp4ALjPGtInIRGPMwdErWyml1PFk0nJfCNQbY3YaY6LA48CyAfN8HlhpjGkD0GBXSqnscmUwTzXQ0O91I7BowDyzAUTkNcAJfMMY8/zxFlpeXm6mT5+eeaVKKaV46623DhljKoaaL5NwlzTTBvbluIBZwIeAGuAVETnLGNN+1IJEbgduB5g6dSp1dXUZfLxSSqk+IvJ+JvNl0i3TCEzp97oG2Jdmnt8YY2LGmF3ANmzYH8UY86AxZoExZkFFxZA7HqWUUsOUSbi/CcwSkVoR8QA3AasGzPMMcCmAiJRju2l2jmShSimlMjdkuBtj4sAdwGpgC/CEMWaTiNwrItemZlsNtIjIZmAt8FVjTMtoFa2UUur4hrwUcrQsWLDAaJ+7UvklFovR2NhIOBzOdik5z+fzUVNTg9vtPmq6iLxljFkw1M9nckJVKaUy0tjYSGFhIdOnT0ck3bUYKhPGGFpaWmhsbKS2tnZYy9DhB5RSIyYcDlNWVqbBfpJEhLKyspM6AtJwV0qNKA32kXGyv8ecC/c3d7fyvdXbiCeS2S5FKaXGrJwL9/V72vmPtfWEYolsl6KUUmNWzoW7z21LDse05a6UOlp7ezs/+tGPTvjnrrrqKtrb24eecYDly5fz5JNPnvDPnQo5GO5OAMLacldKDTBYuCcSx8+L5557jpKSktEqKyty7lJIv8eGu3bLKDW23fPsJjbv6xzRZc6dXMQ/ffTMQd9fsWIFO3bsYN68ebjdbgoKCqiqqmL9+vVs3ryZ6667joaGBsLhMHfeeSe33347ANOnT6euro7u7m6WLl3KRRddxJ/+9Ceqq6v5zW9+g9/vH7K2NWvWcNdddxGPx/nABz7A/fffj9frZcWKFaxatQqXy8WVV17J9773PX71q19xzz334HQ6KS4u5uWXXx6x31GfnAt3n0tb7kqp9L797W+zceNG1q9fz0svvcTVV1/Nxo0bD18r/vDDD1NaWkooFOIDH/gAN9xwA2VlZUctY/v27Tz22GM89NBD3HjjjTz11FPceuutx/3ccDjM8uXLWbNmDbNnz+a2227j/vvv57bbbuPpp59m69atiMjhrp97772X1atXU11dPazuoEzkXLgfbrlHNdyVGsuO18I+VRYuXHjUTUA//OEPefrppwFoaGhg+/btx4R7bW0t8+bNA+D8889n9+7dQ37Otm3bqK2tZfbs2QB8+tOfZuXKldxxxx34fD4+97nPcfXVV3PNNdcAcOGFF7J8+XJuvPFGrr/++pFY1WPkbJ+7dssopYYSDAYPf//SSy/xhz/8gT//+c+88847zJ8/P+1NQl6v9/D3TqeTeDw+5OcMNoyLy+XijTfe4IYbbuCZZ55hyZIlADzwwAP88z//Mw0NDcybN4+WlpEfiivnWu56tYxSajCFhYV0dXWlfa+jo4MJEyYQCATYunUrr7/++oh97pw5c9i9ezf19fXMnDmTRx99lEsuuYTu7m56e3u56qqrWLx4MTNnzgRgx44dLFq0iEWLFvHss8/S0NBwzBHEycq5cPfr1TJKqUGUlZVx4YUXctZZZ+H3+6msrDz83pIlS3jggQc455xzOP3001m8ePGIfa7P5+ORRx7hE5/4xOETql/4whdobW1l2bJlhMNhjDF8//vfB+CrX/0q27dvxxjD5ZdfzrnnnjtitfTJuVEh93eEuOBfX+Rfrz+bmxdOHYXKlFLDtWXLFs4444xsl5E30v0+Mx0VMvf63PVqGaWUGlLudcvode5KqVPsi1/8Iq+99tpR0+68804+85nPZKmioeVcuHtdqROqeimkUuoUWblyZbZLOGE51y0jIvjcDsJxvVpGKaUGk3PhDvaKGb2JSSmlBpe74a597kopNajcC/d3n+SB2D8Qi+oDeJVSajC5F+7dBzknuRkT6cl2JUqpMWa447kD/OAHP6C3t/e480yfPp1Dhw4Na/mnWu6Fu8eOFWGi3VkuRCk11ox2uOeSnLsUsi/cJZY/G0GpvPTfK+DAuyO7zElnw9JvD/p2//HcP/zhDzNx4kSeeOIJIpEIH/vYx7jnnnvo6enhxhtvpLGxkUQiwT/+4z/S1NTEvn37uPTSSykvL2ft2rVDlnLffffx8MMPA/C5z32OL3/5y2mX/Vd/9Vdpx3QfbTkY7gUASFS7ZZRSR+s/nvsLL7zAk08+yRtvvIExhmuvvZaXX36Z5uZmJk+ezO9+9zvADihWXFzMfffdx9q1aykvLx/yc9566y0eeeQR1q1bhzGGRYsWcckll7Bz585jlt3a2pp2TPfRloPhblvuzpiGu1Jj2nFa2KfCCy+8wAsvvMD8+fMB6O7uZvv27Vx88cXcddddfO1rX+Oaa67h4osvPuFlv/rqq3zsYx87PKTw9ddfzyuvvMKSJUuOWXY8Hk87pvtoy9k+d2dcu2WUUoMzxnD33Xezfv161q9fT319PZ/97GeZPXs2b731FmeffTZ33303995777CWnU66ZQ82pvtoyyjcRWSJiGwTkXoRWZHm/eUi0iwi61Nfnxv5UlNS3TKuhIa7Uupo/cdz/8hHPsLDDz9Md7e9+GLv3r0cPHiQffv2EQgEuPXWW7nrrrt4++23j/nZoXzwgx/kmWeeobe3l56eHp5++mkuvvjitMvu7u6mo6ODq666ih/84AesX79+dFZ+gCG7ZUTECawEPgw0Am+KyCpjzOYBs/7SGHPHKNR4tFTLXcNdKTVQ//Hcly5dyi233MIFF1wAQEFBAT/72c+or6/nq1/9Kg6HA7fbzf333w/A7bffztKlS6mqqhryhOp5553H8uXLWbhwIWBPqM6fP5/Vq1cfs+yurq60Y7qPtiHHcxeRC4BvGGM+knp9N4Ax5l/7zbMcWHAi4T7c8dwJtcN3pvHN2K38wz//ByJy4stQSo0KHc99ZI32eO7VQEO/142paQPdICIbRORJEZmSwXKHJ9VyDxAmooOHKaVUWplcLZOuaTywuf8s8JgxJiIiXwB+Clx2zIJEbgduB5g6dZhPUXK6iTs8BCVCKJo4/MBspZQaKYsWLSISiRw17dFHH+Xss8/OUkUnLpNwbwT6t8RrgH39ZzDG9H9090PAd9ItyBjzIPAg2G6ZE6q0n4QzQIAw4bgOHqbUWGOMyfnu0nXr1mW7hEGvyMlUJt0ybwKzRKRWRDzATcCq/jOISFW/l9cCW06qqiEkXAGCEtZhf5UaY3w+Hy0tLScdTOOdMYaWlhZ8Pt+wlzFky90YExeRO4DVgBN42BizSUTuBeqMMauAL4nItUAcaAWWD7uiDCTcQQKEddhfpcaYmpoaGhsbaW5uznYpOc/n81FTUzPsn8/oDlVjzHPAcwOmfb3f93cDdw+7ihNk3AGChAnH9ISqUmOJ2+2mtrY222UocvEOVcC4gwQkQlhb7koplVZOhjveAoJon7tSSg0mJ8NdPEG9WkYppY4jJ8Pd4S0goFfLKKXUoHI23INon7tSSg0m98ZzB5y+ArwSIRKNZbsUpZQak3Ky5e7yFwIQC+sDO5RSKp2cDHen147pnojoQ7KVUiqdnAz3vgd2GA13pZRKK0fD3Q77a6Ia7koplU5OhzsR7XNXSql0cjTcbbeMRDXclVIqnRwNd9tyl7iGu1JKpZPT4e6I6UOylVIqnRwNd9st49KWu1JKpZWj4W5b7q64ttyVUiqd3Ax3l5cEDlwJDXellEonN8NdhKgjgCcZynYlSik1JuVmuAMxpx9PQsNdKaXSyeFwD+A1Gu5KKZVOzoZ73BXAb8LEEvqQbKWUGihnwz3hCuhDspVSahA5G+5Jd8A+RzWmLXellBooh8M9SJCwttyVUiqNnA133EECEiGk4a6UUsfI3XD3FGjLXSmlBpFRuIvIEhHZJiL1IrLiOPN9XESMiCwYuRIH+SxvkABhQpH4aH+UUkrlnCHDXUScwEpgKTAXuFlE5qaZrxD4ErBupItMW5e3AJckiUT0WnellBook5b7QqDeGLPTGBMFHgeWpZnvm8B3gfAI1jeovodkx0Jdp+LjlFIqp2QS7tVAQ7/Xjalph4nIfGCKMea3I1jbcTl9NtwTYX2OqlJKDZRJuEuaaebwmyIO4PvAV4ZckMjtIlInInXNzc2ZV5mG218IQDysLXellBook3BvBKb0e10D7Ov3uhA4C3hJRHYDi4FV6U6qGmMeNMYsMMYsqKioGH7VgCsV7kltuSul1DEyCfc3gVkiUisiHuAmYFXfm8aYDmNMuTFmujFmOvA6cK0xpm5UKk7xBIoASEY03JVSaqAhw90YEwfuAFYDW4AnjDGbROReEbl2tAscjMdv+9yNhrtSSh3DlclMxpjngOcGTPv6IPN+6OTLGpqknqNKTJ+jqpRSA+X0HaoAEtVwV0qpgXI43O1DskVb7kopdYzcDXd3AABnTB+SrZRSA+VuuDschPDhjGu4K6XUQLkb7kDY4ceV0G4ZpZQaKKfDPSI+XAkdOEwppQbK6XCPOgN4NNyVUuoYOR3uMYcfT1L73JVSaqDcDndXAG9SW+5KKTVQTod7whnAZ07J8PFKKZVTcjvc3QH8RlvuSik1UE6He9IVxE8YY8zQMyul1DiS2+HuDhAkQiSezHYpSik1puR0uBt3AV6JEQppv7tSSvWX0+EuXjt4WKhXH7WnlFL95XS49z2NqaujNcuVKKXU2JLT4e4tmQRA96HGLFeilFJjS06He7B8KgDRVg13pZTqL6fDvWhSLQDJjr1ZrkQppcaWnA73YHE5YePG0b0v26UopdSYktPhLg4HzY5yvL0Hsl2KUkqNKTkd7gDtrgqC4YPZLkMppcaUnA/3bs9EiuPN2S5DKaXGlJwP97C/krJkCyR1CAKllOqT8+GeKKzCTZxkt7belVKqT86HO4XVAHQ1v5/lQpRSauzI+XB3l04BoFvDXSmlDsso3EVkiYhsE5F6EVmR5v0viMi7IrJeRF4VkbkjX2p6gXIb7pGWhlP1kUopNeYNGe4i4gRWAkuBucDNacL7F8aYs40x84DvAveNeKWDKC6vImJcJNr1LlWllOqTSct9IVBvjNlpjIkCjwPL+s9gjOns9zIInLJHI5UX+mkyE5AuvUtVKaX6uDKYpxro3+fRCCwaOJOIfBH4W8ADXDYi1WWgxO+mnjIm6V2qSil1WCYtd0kz7ZiWuTFmpTHmNOBrwD+kXZDI7SJSJyJ1zc0jc+miwyG0OssJhJtGZHlKKZUPMgn3RmBKv9c1wPH6QB4Hrkv3hjHmQWPMAmPMgoqKisyrHEKXZyLF0YOgD8pWSikgs3B/E5glIrUi4gFuAlb1n0FEZvV7eTWwfeRKHFrYX4mbGPTqE5mUUgoy6HM3xsRF5A5gNeAEHjbGbBKRe4E6Y8wq4A4RuQKIAW3Ap0ez6IFiwcnQDnTuhWDZqfxopZQakzI5oYox5jnguQHTvt7v+ztHuK4TIkVVsBdMRyNSdU42S1FKqTEh5+9QBXBNSN3I1KaP21NKKciTcPeXVhEzTsKH9C5VpZSCPAn38kI/TUwg3q4td6WUgnwJ9wIvB0wp0ql3qSqlFORZuLt79me7FKWUGhPyItzLCjzsN6X4w016I5NSSpEn4e52OuhwV+BOhiHcnu1ylFIq6/Ii3AF6vJX2m3a9YkYppfIm3DsKTrPfNG3KbiFKKTUG5E24RyecRhgPHNiQ7VKUUirr8ibcywr8bGMa7NdwV0qpvAn38gIv78anYg5s0CtmlFLjXv6Ee6GXTWY6EumE9vezXY5SSmVV3oR7RYGXTcnp9oV2zSilxrm8Cffp5UG2mSkkxaknVZVS417ehPvU0gBxh5dWn55UVUqpvAl3j8vBlAl+drhmaMtdKTXu5U24A8yoKOCd2DTo2g/dzdkuRymlsiavwr22PMhrPZPtC229K6XGsbwK9xkVQf4Ss4/c03BXSo1neRXuteVBOikgHKzRk6pKqXEtr8L9tIoCAA4GZ2nLXSk1ruVVuE8s9BL0ONnhPA1adkCkO9slKaVUVuRVuIsItRVB/hKbChhtvSulxq28CneA2vIC/tAzHcQBO17MdjlKKZUVeRfuM8qDbGl3kaxZBO+tznY5SimVFRmFu4gsEZFtIlIvIivSvP+3IrJZRDaIyBoRmTbypWZmRkUQY6Cl+kO2W6ZzX7ZKUUqprBky3EXECawElgJzgZtFZO6A2f4CLDDGnAM8CXx3pAvN1Ixye8XMtsIL7ITtL2SrFKWUyppMWu4LgXpjzE5jTBR4HFjWfwZjzFpjTG/q5etAzciWmbnp5QEANkQnQ/EUeE/DXSk1/mQS7tVAQ7/Xjalpg/ks8N8nU9TJKPS5mVjoZeehXph1Jex8CeKRbJWjlFJZkUm4S5ppaZ9jJyK3AguAfxvk/dtFpE5E6pqbR29gr9ryILsO9cDsj0CsB3a/OmqfpZRSY1Em4d4ITOn3ugY45iyliFwB/D1wrTEmbVPZGPOgMWaBMWZBRUXFcOrNyIyKAnY2d8P0i8Hl0353pdS4k0m4vwnMEpFaEfEANwGr+s8gIvOB/8QG+8GRL/PEzCgP0tYboy3mgtpL7CWR+tBspdQ4MmS4G2PiwB3AamAL8IQxZpOI3Csi16Zm+zegAPiViKwXkVWDLO6UmFERBGDnoW6YfSW07YKW+myWpJRSp1RG17kbY54zxsw2xpxmjPlWatrXjTGrUt9fYYypNMbMS31de/wljq5zakoAeGNXG8xeYiduejqLFSml1KmVd3eoAlQUepkzqZDX6g9BcQ3UfhDW/1y7ZpRS40ZehjvAhTPLeWN3K+FYAuZ9Etp2w54/Z7sspZQ6JfI23C+aVU40nqRudxuc8VHwFNrWu1JKjQN5G+4Lp5fidgqv1h8CTxDOvA42PQPRnmyXppRSoy5vwz3odTF/6gTb7w62aybaDZuzeiGPUkqdEnkb7gAXzSxn474O2nqiMHUxTKjVrhml1LiQ1+F+4cxyjIE/7WgBEdt63/0KtL2f7dKUUmpU5XW4n1tTTKHXZfvdAc69CcQJf/xOdgtTSqlRltfh7nI6WHxa2ZF+95IpcNHf2K4ZHQpYKZXH8jrcwfa772ntZU9Larj5S/4OJs6FZ78EofbsFqeUUqMk78P94lnlADy/ab+d4PLCdT+C7oOw+v9ksTKllBo9eR/uMyoKWDBtAr9Yt4dkMjX8wOT52j2jlMpreR/uAJ+6YBq7W3p5bcehIxMv+TuomAO/+1uIdGevOKWUGgXjItyXnDWJsqCHR//c7xJIlxc++u/Q0QBr/yV7xSml1CgYF+HudTn5xIIp/GFLE/s7QkfemLoYFvxPWHc/7PtL9gpUSqkRNi7CHeCTi6ZigMfeaDj6jcv/CYIVsOpLkIhnpTallBpp4ybcp5QG+NDsCh5/Yw+xRPLIG/4SWPpdOLABXvt+9gpUSqkRNG7CHeDWxdM42BXhuXf3H/3G3GVw1g3w4rdg63PZKU4ppUbQuAr3D50+kdMrC/m31dvsQzz6iMC1/wGT58FTn4P9G7JXpFJKjYBxFe5Oh/D1j86lsS3ET17ddfSbngDc/Dj4iuGxm6HrQHaKVEqpETCuwh3sSJFXzq1k5dp6mjrDR79ZOAlueRxCrfDAxfCXn0EymX5BSik1ho27cAf4+6vPIJ4wfPf5bce+WXUufOY5mDAdfvNFeOhS2Pv2Ka9RKaVOxrgM92llQT5z0XSeeruR9Q1pBg+bPB8++wJc/2M7Bs1Pr9WAV0rllHEZ7gB3XDqTiYVevvbkhqNPrvYRgXM+AZ9fA4EJ8LMboDlNS18ppcagcRvuhT433/n4OWxr6uK+3783+IxFk+FTz4DDBY9+DNobBp9XKaXGiHEb7gCXnj6RWxZN5aFXdrJuZ8vgM5adBp962j5g+8eXw+bfgDGnrlCllDpB4zrcAf7+qjOYWhrgK796h65wbPAZJ50Fy38HBZXwxG3w+C3Q0XjqClVKqROQUbiLyBIR2SYi9SKyIs37HxSRt0UkLiIfH/kyR0/Q6+K+G89lX3uIFU+9e2TM93QmnQ2fXwsf/ibsWAs/ugDW/0Jb8UqpMWfIcBcRJ7ASWArMBW4WkbkDZtsDLAd+MdIFngrnTytlxdI5/O7d/Xzn+a3Hn9npggu/BH/9Z6g8C5753/DLW6Hn0PF/TimlTiFXBvMsBOqNMTsBRORxYBmwuW8GY8zu1Hs5e8fP5y+eQUNriP98eSc1E/x86oLpx/+B0lpY/lv480p48Ztw3xlQeaa9jHL6xTD3OnCM+14vpVSWZJI+1UD/S0QaU9PyiojwTx+dyxVnTOSfVm3i+Y37h/4hh9O24v/Xy7DoC+AthHefhCc/Az+9Bg5tH/3ClVIqjUzCXdJMG1Yns4jcLiJ1IlLX3Nw8nEWMKpfTwQ9vns85NSX89c/f5pHXdg39QwATz4Arvwmffha+9j4sWwlNG+H+C+GP34Xe1tEtXCmlBsgk3BuBKf1e1wD7hvNhxpgHjTELjDELKioqhrOIURfwuPjF5xdx+RmV3PPsZr6xahOJ451kHcjhgPm3whffhNOXwNpvwf+dY0eb3LEWor2jV7xSSqVk0uf+JjBLRGqBvcBNwC2jWlWWBTwuHrj1fL7931t46JVdvNfUxbevP4epZYHMF1JYCTf+FxzYCG//FDb8Et79FYjT9s1PWQhzrrH9885MNoNSSmVOTAaX8YnIVcAPACfwsDHmWyJyL1BnjFklIh8AngYmAGHggDHmzOMtc8GCBaauru6kV2C0PVHXwL3PbiaRNHzlytl85sJanI50PVVDiIVg50vQ+CY01tmvWI99xN/c62Dh56Hi9BGvXymVX0TkLWPMgiHnyyTcR0OuhDvA/o4Q//D0RtZsPcjcqiL+bsnpXDK7ApFhhHyfWAi2/x42PgXvPQ/xsG3JL/oCdO237+15HU67FK74BgRKR2p1lFI5TMN9hBljDl8H39AaYlFtKV9bOofzpk44+YX3HII3HoR1/wnh1CiVgXKoPg/q14CvyAb8vFuP7cLpaQFvAbi8J1+HUmrM03AfJdF4ksff3MMP12znUHeUj82v5mtL5jCp2HfyC49021Z8aS1UzbcnZ5s2w3N3wfuvgdMDZbNs902k0/bndx+Awsmw5F9s987JHE0opcY8DfdR1hOJ86OX6nno5V24nMJnL6rlqrOrmDOp8OS6a9IxBrb9NzSsg4NboHmrvaZ+0tk26Dc+BQfehRkfgov+Fspn26dKiUAsDF37wOGGkilDfZJSaozTcD9F9rT08q3nNrN6UxMA1SV+rjyzkk8tnsaMioJTU0QyAXUPw5pvQqTDTnMHbFdNqO3IfBVzYPYSmHm5/T5YoS19pXKMhvspdrAzzItbD/KHLQd5+b1mookkl82ZyG0XTOOC08rwupyjX0RvK+z7C7TuhNZd9iRtUZXttgm32y6f9/8Eybid31cMJdPA7bc7Am8RTJ4HNR+wwyh4i0Y2/EPtIA57DkEpNSwa7ll0sCvMz1/fw8/Xvc+h7ih+t5NFM0q5aGY586aUMHdyEQFPlq5tD7XD3jo4VA+H3oOOBrsTiEehtwVa+g2Z4HCBp8B+YewRgjig9oP2KVW1H4LORti8yu44Yr32iMEdsDuIebfYrqBIF7z27/Cn/7DLvPBLsPiv7YlgpdQJ0XAfA8KxBK9sP8Sr25t5Zfshdh7qAcAhMLuykCvnVnLtvMnMnFiY5Ur7CbXB3rdsH3640wZztMe24MVx5BLOSIdt2Uc67c9NOsf280d77XsH3gUEai+25wl6muHM6yEZgy3PQnAinPtX9qog/wS7g2naaE8Sd+478nnugD2vUHkmFE+BUKt9rm20B6rPt8svmQaJGLTttl89zXZHFW634++XnmYfeJ6M2fd6Dtn1ivXar6IamLoYSqbadWnbBQ1vgklA1Tx7DsPpgmTS/nzTu/Zu4/o1djkf/ArMv+3IlUzN78Hul8HlA08QfCW21v5HLMbY5wG07rA1d+y1Ncy4NP2Ac8bYzxanvSx2NLrTuppg/ztQs+DYS29NaueejNsvd2DwgfFC7bDp1/YCgcoz7bmhgolHz5OIwXur7baedQWUzki/LGPsPE63PcIE+7jLAxugZYd9Ulr56faBOiL2/2csBP4SKJgEntSNh9HeI/93ug5Ad5P9vzH9ouMfScYjcHCz/b3EQjDn6iP/T/okk8f+LroOQMMb9u/gwLv2aLr6fDjjGjjtsiPrMgwa7mNQU2eYdxs72LC3gzd2tbBuVyvGwJxJhVw4s5zzp03gvKkTRubKm9EUC8P2F+wfZ8VsmLvMhmd/be/DO4/BhieguBou/wbUnG/fa3gT1txjr+NP9ntAir/UPhSlZFpqgoFwBxzcakPQpAYddQfsH3u448jPhduPvN9HHMdOO57CyZCIQu+A4Ztdfht23U1HurScXph2gf2Db1gHFWfAOTfCtufsjWoDidNe2lq9wP6h733r2M8BmFAL53/anjBv2WnXu3UXtO+BeMjO43DbHak7YH9/ibgNNnfAhoYnaHeY/hI7b6jV7uyiPXYeTzC10ym2O55k3N5gd2BDavkue3J+9hL7uY1vwr71Rz6/73frK4FAGUyYZs/hlM2082789dHzgg3a6vPsV6gd3nn86PWfONeGXsk0G9gY24jY/oJtWo5HAAAOE0lEQVS97yMdp8dur+PxFNrfUTyc/n2Hyx5lFlbZQO7ab5+41ifUfvT/UYCahXZHfGi7bZB07oXiGruD8pfartG2XUd+T+Wz7Xo1rLP/T90BuOp7MP+Tx699EBruOeBgZ5jfbtjP85sO8E5DO5G4DaLJxT7OSwX93MlFzK4spDToyXK1o8AYGzjhdvtHVlA5eIs0FraXfQbKbXeOMbYFt/sV26oqrLKttwm1duiHQJntTuppti28tt32vEKw3C7DV5Q66eyzAbrndfvldNuhIaYsssG4fz3sfdvuSIqq7OeUzoCpF9hWoTH2SOT3X7d/0BVn2D/aMz5q/7Aj3bbu3a/Brj/akCybaVtx1efZP/wJ0229W38HdT+BPX+26+zy288qrbXhMGGa/bzuA9C53waWw2VrTiZsoMZC9jPD7fYoLBG1yw6U23pjIfs7j3TZo65wh13mlEW2BT15Puz8o215t++xAVp1rq03UGZHQnW47Gf0ttiv1p22iy8etr/zsz9hd1DFU234NW2022jv27bbz+GC05fC/E9B+SzY9rxd94Z1RweppxBmXmaH6ABbezJuf2eTzrYt6N4W+9ktO1JHen67TcPtR1roTk9qZzfBHkEUTrL/11p3wY4XYedae5RaWGXf8xYe+X/oLbLrP3m+nbbx1/bqtIObj9RRXGOPwlp22KPCqnNs+E9ZbBsrfa30RAx2vwpbfwvn3nKksXOCNNxzTDSeZPP+Tt56v42397Txl/fb2NdxpLVRXuDhopnlLJtXzUWzynE7daz4MSUetZeclkw7fpeJMUN3qbTtTrXOq0b/mQB93S0Db44zxu6sCieDO4MjyWTCnr8JVtijgsGEUjfp+UvSLCNpW/Ode213yOTzwDVGGzXJhN3RZYGGex5o6gyz9UAX25u62Ly/kxe3HqS9N0Zp0MOcSYUEPC6CXidzq4q4/rwaKgr1LlWl8p2Gex6KxpO8/F4zv92wj8a2EL3RBF2RGA2tIVwO4bI5E7l0zkQqi7xUFPiYUuqnJDBGWz5KqWHJNNx1rNkc4nE5uGJuJVfMrTxqev3Bbn5V18BTbzfywuamo96rLvFzdnUxc6oKmV4WZGpZgGmlAUqDnpG/k1YpNWZoyz2PxBNJmroiHOwMc7Arwq5DPWzc28HGvR3sbjn6ISF+t5PqCX4qi7x4XU7cTqHA6+a8aSUsqi3jtIqghr9SY5C23Mchl9NBdYmf6pJjr6ENxxI0tPbyfksve1p72dseYm9biINdYTpDcaLxJC09UZ56uxGAkoCbSUU+SgJuJgQ8FPncFPpcFPvdTC8PcvqkQmrLg3piV6kxSsN9nPC5ncyqLGRW5eA3TBlj2N3Sy7qdLbzT2E5Ld5S23ijbD3bTFY7RGYoTiiUOz+92ClXFfiaX+Jhc7KfI78bvcRJwOynwuSjwuij0uakq9jGjIkihz30qVlUphYa76kdEqC0PUlse5KaFU9POE44l2Nncw3tNXWxr6mJvW4h97SHW7WqlMxwjHEsQS6Tv6qss8lIa9NLXFegQweNy4HE5KA14mFNVyJxJRcyqLKCq2Je9IRqUygP616NOiM/tZO7kIuZOHvyW7Wg8SW80Tlc4Tmc4xt62EDuae6g/2E1nOEZfT37SGCLxJNF4km1NXazefID+p4AKfS7KC7y4nYLb6cDldOByCC6H4HU7qSjwUlnkpbLIR4HXXhYa9LooC3qpKPRSGvQM75GISuUBDXc14mxr3HP4MswzJxdn9HOhaIJtTV3sOtTNgY4ITZ1hWnqixOJJ4skk0YQhkUwSTxg6QjHqm7o42BUhnkx/pOAQCHpcBL0uAh4nCWMIxxKEY0lcDsHnduL3OCkNeJhY5GVSkY9JxT4qU/+WBT0Ups41+NxOjDEkje2+cjpETzirMU3DXY0Zfo+TeVNKmDclzd2Lg0gmDa29UXoicXoiCbojcVq6IzR3RzjUFaEzHKc3at9zOQWfy4nP7SCeNIRiCcKxBIe6o2zc28EftjQRjmU+Fo1DIOBxUTPBz5TSANUlfgp9Lgp9LvxuJ9GEIRJPkEgYivxuSgJuiv1uHCIkU4coRX43ZUEPE4IeTJLDNRWn5tcdiBouDXeV0xwOobzAS3nByd+da4yhMxTnQGeYA51h2nqi9kRyOE4knsQh9jwBQCJpSCQN3ZE4jW297Gnp5fWdLXRH4ozU1cU+t4OqYj+lQQ/Ffrtj8LkdiAgOAbfTQcDjJOCxRyb2BLYLv8eF2yG2G8speJyOVLeW7dJyiOBKdXV5XA48Tgdel0N3JHlGw12pFBGhOOCmOODm9EnDG4bZGENPNEFvNI7X6cTrduAQoTMco703SkcodvizjIHOUIyWnihtPVGcDsHvceJxOmgPxdjfHmJ/aifT1BnmvaYuovEkSWPPV8TiSXpjCRKDdEudCI/TQZHfTVGqC8rntsEfSx19RGJJXE4HPrfdEZQGPVQU2HMbxQEPhV57dZTX7cDpEFwOx+FzJR6XPVfSt4MBe14mEk/idAiTinwEvRpFI01/o0qNIBGhIBV0/Y3U0cVAxhiiiSQ9kQQ9EXsSOxSLE0sY4glDLHWOIpZIEkskSSQN8dRRRyyRPByyfSe/O0MxwrHk4UD3uR2U+N24nbYrKxJP2HMjB7p4tesQneH4iKxHkc9FScBzuKakMfZoJbXjMBiSqR6zYr+bCUE3RX63HVg0dU7G57In1INep+12i9paRcCZ2tn0HfX0XakV9LoIeuzPFXpdFKS61JypnVHfv26n4HAIydTvzgBel+PwDYBDHfXEE0kcYpdxqmi4K5XDRASvy4nX5czKsNDhWIKucJyucIzuiL0ZLpYwxJNJ4kl7dBHrt3PpO/ntdfUdGSQ50BHhQEeI9lAMT6qlLwKdoTjtoRhd4RgOEZypcxU7D3XTtidGRyiGUwS303ZBhaKJo+7DEAFf6vGWiaTd0Y3GDfkOgWBqh+73OMFAwtida9/5nmgieXhel8PBPcvO5OZBLjceKRruSqlhs104zjEzImkiaQPVfZzzCMbY1nf/I56e1KW73WF7o17fEU48kSSW2kkljTl8vgKOdC2FovZEfk8kTu/hIwXB6ZCjrtZKmiNHU8Pt9jsRGu5KqbzhdMiQd0JLKqBdTgcBj2vM7JhGWkYDg4jIEhHZJiL1IrIizfteEfll6v11IjJ9pAtVSimVuSHDXUScwEpgKTAXuFlE5g6Y7bNAmzFmJvB94DsjXahSSqnMZdJyXwjUG2N2GmOiwOPAsgHzLAN+mvr+SeBy0YtmlVIqazIJ92qgod/rxtS0tPMYY+JAB1A2EgUqpZQ6cZmEe7oW+MALijKZBxG5XUTqRKSuubk5k/qUUkoNQybh3ghM6fe6Btg32Dwi4gKKgdaBCzLGPGiMWWCMWVBRUTG8ipVSSg0pk3B/E5glIrUi4gFuAlYNmGcV8OnU9x8HXjTZen6fUkqpoa9zN8bEReQOYDXgBB42xmwSkXuBOmPMKuAnwKMiUo9tsd80mkUrpZQ6vqw9IFtEmoH3h/nj5cChESwnV4zH9R6P6wzjc73H4zrDia/3NGPMkP3aWQv3kyEidZk8/TvfjMf1Ho/rDONzvcfjOsPorbc+ul4ppfKQhrtSSuWhXA33B7NdQJaMx/Uej+sM43O9x+M6wyitd072uSullDq+XG25K6WUOo6cC/ehhh/OByIyRUTWisgWEdkkInemppeKyO9FZHvq3wnZrnWkiYhTRP4iIr9Nva5NDSO9PTWs9Kl/3NAoE5ESEXlSRLamtvkF42Rb/03q//dGEXlMRHz5tr1F5GEROSgiG/tNS7ttxfphKts2iMh5J/PZORXuGQ4/nA/iwFeMMWcAi4EvptZzBbDGGDMLWJN6nW/uBLb0e/0d4PupdW7DDi+db/4deN4YMwc4F7v+eb2tRaQa+BKwwBhzFvYGyZvIv+39/4AlA6YNtm2XArNSX7cD95/MB+dUuJPZ8MM5zxiz3xjzdur7LuwfezVHD638U+C67FQ4OkSkBrga+HHqtQCXYYeRhvxc5yLgg9i7vDHGRI0x7eT5tk5xAf7UeFQBYD95tr2NMS9z7Dhbg23bZcB/Get1oEREqob72bkW7pkMP5xXUk+1mg+sAyqNMfvB7gCAidmrbFT8APg7IPWce8qA9tQw0pCf23sG0Aw8kuqO+rGIBMnzbW2M2Qt8D9iDDfUO4C3yf3vD4Nt2RPMt18I9o6GF84WIFABPAV82xnRmu57RJCLXAAeNMW/1n5xm1nzb3i7gPOB+Y8x8oIc864JJJ9XPvAyoBSYDQWy3xED5tr2PZ0T/v+dauGcy/HBeEBE3Nth/boz5dWpyU99hWurfg9mqbxRcCFwrIrux3W2XYVvyJanDdsjP7d0INBpj1qVeP4kN+3ze1gBXALuMMc3GmBjwa+B/kP/bGwbftiOab7kW7pkMP5zzUn3NPwG2GGPu6/dW/6GVPw385lTXNlqMMXcbY2qMMdOx2/VFY8wngbXYYaQhz9YZwBhzAGgQkdNTky4HNpPH2zplD7BYRAKp/+99653X2ztlsG27CrgtddXMYqCjr/tmWIwxOfUFXAW8B+wA/j7b9YzSOl6EPRzbAKxPfV2F7YNeA2xP/Vua7VpHaf0/BPw29f0M4A2gHvgV4M12faOwvvOAutT2fgaYMB62NXAPsBXYCDwKePNtewOPYc8pxLAt888Otm2x3TIrU9n2LvZKomF/tt6hqpRSeSjXumWUUkplQMNdKaXykIa7UkrlIQ13pZTKQxruSimVhzTclVIqD2m4K6VUHtJwV0qpPPT/AXkpvofVgypHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting our losses\n",
    "%matplotlib inline\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "plt.plot(train_loss, label='train_loss')\n",
    "plt.plot(test_loss, label='test_loss')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow as a graph constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the graph\n",
    "\n",
    "a = tf.Variable(4)\n",
    "b = tf.Variable(5)\n",
    "\n",
    "c = a + b\n",
    "d = a + c * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting a session\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = sess.run(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "# Printing the output\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, 30))\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None, 1))\n",
    "\n",
    "hid = tf.layers.dense(X, 30, activation=tf.nn.relu)\n",
    "y_hat = tf.layers.dense(hid, 1, activation=tf.nn.sigmoid)\n",
    "\n",
    "loss = tf.losses.log_loss(y, y_hat)\n",
    "optimizer = tf.train.AdamOptimizer(0.01)\n",
    "training_run = optimizer.minimize(loss)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3776223776223776"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for _ in range(100):\n",
    "        sess.run(training_run, feed_dict={X: X_train_s, y: y_train.reshape(-1, 1)})\n",
    "        \n",
    "    pred = sess.run(y_hat, feed_dict={X: X_test})\n",
    "\n",
    "classes = (pred > 0.5).astype(int)\n",
    "\n",
    "metrics.accuracy_score(y_test.reshape(-1, 1), classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
